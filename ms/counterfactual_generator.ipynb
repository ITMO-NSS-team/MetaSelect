{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>f__pymfe.statistical.nr_disc</th>\n",
       "      <th>f__pymfe.landmarking.linear_discr.mean</th>\n",
       "      <th>f__pymfe.model-based.leaves_per_class.min</th>\n",
       "      <th>f__pymfe.landmarking.linear_discr.max</th>\n",
       "      <th>f__pymfe.landmarking.worst_node.min</th>\n",
       "      <th>f__pymfe.model-based.leaves_per_class.max</th>\n",
       "      <th>f__pymfe.landmarking.elite_nn.max</th>\n",
       "      <th>f__pymfe.landmarking.elite_nn.mean</th>\n",
       "      <th>f__pymfe.model-based.var_importance.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>f__pymfe.statistical.t_mean.min</th>\n",
       "      <th>f__pymfe.info-theory.class_ent</th>\n",
       "      <th>f__pymfe.landmarking.one_nn.skewness</th>\n",
       "      <th>f__pymfe.landmarking.linear_discr.kurtosis</th>\n",
       "      <th>f__pymfe.landmarking.one_nn.kurtosis</th>\n",
       "      <th>f__pymfe.landmarking.elite_nn.kurtosis</th>\n",
       "      <th>f__pymfe.landmarking.random_node.skewness</th>\n",
       "      <th>f__pymfe.general.nr_bin</th>\n",
       "      <th>f__pymfe.general.freq_class.skewness</th>\n",
       "      <th>f__pymfe.statistical.sparsity.skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openml__Amazon_employee_access__34539</td>\n",
       "      <td>-0.717694</td>\n",
       "      <td>-0.058807</td>\n",
       "      <td>0.300973</td>\n",
       "      <td>-0.079564</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.325937</td>\n",
       "      <td>-0.032274</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-0.346265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-1.809913</td>\n",
       "      <td>-0.060385</td>\n",
       "      <td>-0.054699</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.056088</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>-0.191565</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openml__Australian__146818</td>\n",
       "      <td>-0.717694</td>\n",
       "      <td>0.331661</td>\n",
       "      <td>1.057782</td>\n",
       "      <td>0.367881</td>\n",
       "      <td>0.740437</td>\n",
       "      <td>0.434462</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>1.012217</td>\n",
       "      <td>0.851732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>-0.357676</td>\n",
       "      <td>1.098362</td>\n",
       "      <td>-1.021351</td>\n",
       "      <td>-0.555947</td>\n",
       "      <td>0.855549</td>\n",
       "      <td>0.123710</td>\n",
       "      <td>1.242876</td>\n",
       "      <td>-0.191565</td>\n",
       "      <td>-0.448708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openml__GesturePhaseSegmentationProcessed__14969</td>\n",
       "      <td>1.259443</td>\n",
       "      <td>-1.817603</td>\n",
       "      <td>-0.986897</td>\n",
       "      <td>-1.902905</td>\n",
       "      <td>-1.003490</td>\n",
       "      <td>-1.269771</td>\n",
       "      <td>-1.487765</td>\n",
       "      <td>-1.321889</td>\n",
       "      <td>-0.921948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.862327</td>\n",
       "      <td>2.441022</td>\n",
       "      <td>0.364990</td>\n",
       "      <td>1.384655</td>\n",
       "      <td>-0.811672</td>\n",
       "      <td>0.987377</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>-0.393988</td>\n",
       "      <td>0.445351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openml__JapaneseVowels__3510</td>\n",
       "      <td>1.591767</td>\n",
       "      <td>1.524092</td>\n",
       "      <td>-1.384178</td>\n",
       "      <td>1.181988</td>\n",
       "      <td>-1.404434</td>\n",
       "      <td>-1.512919</td>\n",
       "      <td>-1.618540</td>\n",
       "      <td>-1.479737</td>\n",
       "      <td>-0.205008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003942</td>\n",
       "      <td>1.374531</td>\n",
       "      <td>1.383925</td>\n",
       "      <td>2.366672</td>\n",
       "      <td>2.342461</td>\n",
       "      <td>0.508524</td>\n",
       "      <td>-0.608309</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>1.237712</td>\n",
       "      <td>0.792441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openml__LED-display-domain-7digit__125921</td>\n",
       "      <td>1.548884</td>\n",
       "      <td>0.395620</td>\n",
       "      <td>-1.313345</td>\n",
       "      <td>0.528443</td>\n",
       "      <td>-1.330861</td>\n",
       "      <td>-1.745805</td>\n",
       "      <td>-1.836716</td>\n",
       "      <td>-1.835557</td>\n",
       "      <td>0.649553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>1.450634</td>\n",
       "      <td>-0.651210</td>\n",
       "      <td>-1.129312</td>\n",
       "      <td>0.390232</td>\n",
       "      <td>-0.654665</td>\n",
       "      <td>-0.479809</td>\n",
       "      <td>1.480583</td>\n",
       "      <td>-3.100597</td>\n",
       "      <td>-0.028891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>openml__walking-activity__9945</td>\n",
       "      <td>1.259443</td>\n",
       "      <td>-2.557019</td>\n",
       "      <td>-1.474528</td>\n",
       "      <td>-2.391917</td>\n",
       "      <td>-1.829047</td>\n",
       "      <td>-1.879539</td>\n",
       "      <td>-2.532650</td>\n",
       "      <td>-2.508885</td>\n",
       "      <td>1.352984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014311</td>\n",
       "      <td>1.694992</td>\n",
       "      <td>0.765007</td>\n",
       "      <td>-0.749477</td>\n",
       "      <td>-0.788399</td>\n",
       "      <td>0.402050</td>\n",
       "      <td>0.413781</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>2.107292</td>\n",
       "      <td>-1.141123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>openml__wall-robot-navigation__9960</td>\n",
       "      <td>1.016480</td>\n",
       "      <td>-0.528458</td>\n",
       "      <td>-1.381179</td>\n",
       "      <td>-0.864932</td>\n",
       "      <td>-0.640228</td>\n",
       "      <td>-0.233640</td>\n",
       "      <td>-0.433528</td>\n",
       "      <td>-0.243242</td>\n",
       "      <td>-0.714794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.488152</td>\n",
       "      <td>0.279138</td>\n",
       "      <td>0.957285</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.308066</td>\n",
       "      <td>0.657043</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>-0.454751</td>\n",
       "      <td>-0.038036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>openml__wdbc__9946</td>\n",
       "      <td>-0.717694</td>\n",
       "      <td>1.630453</td>\n",
       "      <td>0.765622</td>\n",
       "      <td>1.629772</td>\n",
       "      <td>0.645144</td>\n",
       "      <td>0.707926</td>\n",
       "      <td>1.702328</td>\n",
       "      <td>2.001674</td>\n",
       "      <td>-0.879193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-0.415777</td>\n",
       "      <td>-1.009984</td>\n",
       "      <td>1.566987</td>\n",
       "      <td>-1.482758</td>\n",
       "      <td>1.097915</td>\n",
       "      <td>0.168089</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>-0.191565</td>\n",
       "      <td>0.174857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>-0.717694</td>\n",
       "      <td>-0.796536</td>\n",
       "      <td>0.932306</td>\n",
       "      <td>-0.968045</td>\n",
       "      <td>0.645144</td>\n",
       "      <td>0.547540</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.153663</td>\n",
       "      <td>1.085436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>-1.859142</td>\n",
       "      <td>-0.577274</td>\n",
       "      <td>-0.585525</td>\n",
       "      <td>-1.244723</td>\n",
       "      <td>-1.902582</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>-0.853296</td>\n",
       "      <td>-0.191565</td>\n",
       "      <td>-0.489966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>openml__yeast__145793</td>\n",
       "      <td>1.016480</td>\n",
       "      <td>-0.242851</td>\n",
       "      <td>-1.268092</td>\n",
       "      <td>-0.349227</td>\n",
       "      <td>-0.879987</td>\n",
       "      <td>-0.596432</td>\n",
       "      <td>-0.598965</td>\n",
       "      <td>-0.513005</td>\n",
       "      <td>0.474611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>0.641061</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>-1.945548</td>\n",
       "      <td>-0.248721</td>\n",
       "      <td>1.717795</td>\n",
       "      <td>-2.654731</td>\n",
       "      <td>0.396114</td>\n",
       "      <td>-0.540946</td>\n",
       "      <td>-0.009419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dataset_name  \\\n",
       "0               openml__Amazon_employee_access__34539   \n",
       "1                          openml__Australian__146818   \n",
       "2    openml__GesturePhaseSegmentationProcessed__14969   \n",
       "3                        openml__JapaneseVowels__3510   \n",
       "4           openml__LED-display-domain-7digit__125921   \n",
       "..                                                ...   \n",
       "129                    openml__walking-activity__9945   \n",
       "130               openml__wall-robot-navigation__9960   \n",
       "131                                openml__wdbc__9946   \n",
       "132                              openml__wilt__146820   \n",
       "133                             openml__yeast__145793   \n",
       "\n",
       "     f__pymfe.statistical.nr_disc  f__pymfe.landmarking.linear_discr.mean  \\\n",
       "0                       -0.717694                               -0.058807   \n",
       "1                       -0.717694                                0.331661   \n",
       "2                        1.259443                               -1.817603   \n",
       "3                        1.591767                                1.524092   \n",
       "4                        1.548884                                0.395620   \n",
       "..                            ...                                     ...   \n",
       "129                      1.259443                               -2.557019   \n",
       "130                      1.016480                               -0.528458   \n",
       "131                     -0.717694                                1.630453   \n",
       "132                     -0.717694                               -0.796536   \n",
       "133                      1.016480                               -0.242851   \n",
       "\n",
       "     f__pymfe.model-based.leaves_per_class.min  \\\n",
       "0                                     0.300973   \n",
       "1                                     1.057782   \n",
       "2                                    -0.986897   \n",
       "3                                    -1.384178   \n",
       "4                                    -1.313345   \n",
       "..                                         ...   \n",
       "129                                  -1.474528   \n",
       "130                                  -1.381179   \n",
       "131                                   0.765622   \n",
       "132                                   0.932306   \n",
       "133                                  -1.268092   \n",
       "\n",
       "     f__pymfe.landmarking.linear_discr.max  \\\n",
       "0                                -0.079564   \n",
       "1                                 0.367881   \n",
       "2                                -1.902905   \n",
       "3                                 1.181988   \n",
       "4                                 0.528443   \n",
       "..                                     ...   \n",
       "129                              -2.391917   \n",
       "130                              -0.864932   \n",
       "131                               1.629772   \n",
       "132                              -0.968045   \n",
       "133                              -0.349227   \n",
       "\n",
       "     f__pymfe.landmarking.worst_node.min  \\\n",
       "0                               0.377100   \n",
       "1                               0.740437   \n",
       "2                              -1.003490   \n",
       "3                              -1.404434   \n",
       "4                              -1.330861   \n",
       "..                                   ...   \n",
       "129                            -1.829047   \n",
       "130                            -0.640228   \n",
       "131                             0.645144   \n",
       "132                             0.645144   \n",
       "133                            -0.879987   \n",
       "\n",
       "     f__pymfe.model-based.leaves_per_class.max  \\\n",
       "0                                     0.325937   \n",
       "1                                     0.434462   \n",
       "2                                    -1.269771   \n",
       "3                                    -1.512919   \n",
       "4                                    -1.745805   \n",
       "..                                         ...   \n",
       "129                                  -1.879539   \n",
       "130                                  -0.233640   \n",
       "131                                   0.707926   \n",
       "132                                   0.547540   \n",
       "133                                  -0.596432   \n",
       "\n",
       "     f__pymfe.landmarking.elite_nn.max  f__pymfe.landmarking.elite_nn.mean  \\\n",
       "0                            -0.032274                            0.000554   \n",
       "1                             0.826934                            1.012217   \n",
       "2                            -1.487765                           -1.321889   \n",
       "3                            -1.618540                           -1.479737   \n",
       "4                            -1.836716                           -1.835557   \n",
       "..                                 ...                                 ...   \n",
       "129                          -2.532650                           -2.508885   \n",
       "130                          -0.433528                           -0.243242   \n",
       "131                           1.702328                            2.001674   \n",
       "132                           0.000875                            0.153663   \n",
       "133                          -0.598965                           -0.513005   \n",
       "\n",
       "     f__pymfe.model-based.var_importance.mean  ...  \\\n",
       "0                                   -0.346265  ...   \n",
       "1                                    0.851732  ...   \n",
       "2                                   -0.921948  ...   \n",
       "3                                   -0.205008  ...   \n",
       "4                                    0.649553  ...   \n",
       "..                                        ...  ...   \n",
       "129                                  1.352984  ...   \n",
       "130                                 -0.714794  ...   \n",
       "131                                 -0.879193  ...   \n",
       "132                                  1.085436  ...   \n",
       "133                                  0.474611  ...   \n",
       "\n",
       "     f__pymfe.statistical.t_mean.min  f__pymfe.info-theory.class_ent  \\\n",
       "0                           0.001745                       -1.809913   \n",
       "1                           0.016592                       -0.357676   \n",
       "2                           0.001690                        0.862327   \n",
       "3                          -0.003942                        1.374531   \n",
       "4                           0.004824                        1.450634   \n",
       "..                               ...                             ...   \n",
       "129                        -0.014311                        1.694992   \n",
       "130                         0.008032                        0.488152   \n",
       "131                         0.001723                       -0.415777   \n",
       "132                         0.139038                       -1.859142   \n",
       "133                        -0.001497                        0.641061   \n",
       "\n",
       "     f__pymfe.landmarking.one_nn.skewness  \\\n",
       "0                               -0.060385   \n",
       "1                                1.098362   \n",
       "2                                2.441022   \n",
       "3                                1.383925   \n",
       "4                               -0.651210   \n",
       "..                                    ...   \n",
       "129                              0.765007   \n",
       "130                              0.279138   \n",
       "131                             -1.009984   \n",
       "132                             -0.577274   \n",
       "133                              0.092764   \n",
       "\n",
       "     f__pymfe.landmarking.linear_discr.kurtosis  \\\n",
       "0                                     -0.054699   \n",
       "1                                     -1.021351   \n",
       "2                                      0.364990   \n",
       "3                                      2.366672   \n",
       "4                                     -1.129312   \n",
       "..                                          ...   \n",
       "129                                   -0.749477   \n",
       "130                                    0.957285   \n",
       "131                                    1.566987   \n",
       "132                                   -0.585525   \n",
       "133                                   -1.945548   \n",
       "\n",
       "     f__pymfe.landmarking.one_nn.kurtosis  \\\n",
       "0                                0.011987   \n",
       "1                               -0.555947   \n",
       "2                                1.384655   \n",
       "3                                2.342461   \n",
       "4                                0.390232   \n",
       "..                                    ...   \n",
       "129                             -0.788399   \n",
       "130                              0.014126   \n",
       "131                             -1.482758   \n",
       "132                             -1.244723   \n",
       "133                             -0.248721   \n",
       "\n",
       "     f__pymfe.landmarking.elite_nn.kurtosis  \\\n",
       "0                                  0.056088   \n",
       "1                                  0.855549   \n",
       "2                                 -0.811672   \n",
       "3                                  0.508524   \n",
       "4                                 -0.654665   \n",
       "..                                      ...   \n",
       "129                                0.402050   \n",
       "130                                0.308066   \n",
       "131                                1.097915   \n",
       "132                               -1.902582   \n",
       "133                                1.717795   \n",
       "\n",
       "     f__pymfe.landmarking.random_node.skewness  f__pymfe.general.nr_bin  \\\n",
       "0                                     0.045381                -0.853296   \n",
       "1                                     0.123710                 1.242876   \n",
       "2                                     0.987377                -0.853296   \n",
       "3                                    -0.608309                -0.853296   \n",
       "4                                    -0.479809                 1.480583   \n",
       "..                                         ...                      ...   \n",
       "129                                   0.413781                -0.853296   \n",
       "130                                   0.657043                -0.853296   \n",
       "131                                   0.168089                -0.853296   \n",
       "132                                   0.045381                -0.853296   \n",
       "133                                  -2.654731                 0.396114   \n",
       "\n",
       "     f__pymfe.general.freq_class.skewness  \\\n",
       "0                               -0.191565   \n",
       "1                               -0.191565   \n",
       "2                               -0.393988   \n",
       "3                                1.237712   \n",
       "4                               -3.100597   \n",
       "..                                    ...   \n",
       "129                              2.107292   \n",
       "130                             -0.454751   \n",
       "131                             -0.191565   \n",
       "132                             -0.191565   \n",
       "133                             -0.540946   \n",
       "\n",
       "     f__pymfe.statistical.sparsity.skewness  \n",
       "0                                  0.002694  \n",
       "1                                 -0.448708  \n",
       "2                                  0.445351  \n",
       "3                                  0.792441  \n",
       "4                                 -0.028891  \n",
       "..                                      ...  \n",
       "129                               -1.141123  \n",
       "130                               -0.038036  \n",
       "131                                0.174857  \n",
       "132                               -0.489966  \n",
       "133                               -0.009419  \n",
       "\n",
       "[134 rows x 124 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv('data/features__power.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('data/metrics__perf_abs.csv')\n",
    "models = targets.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>LinearModel__absperf</th>\n",
       "      <th>RandomForest__absperf</th>\n",
       "      <th>XGBoost__absperf</th>\n",
       "      <th>rtdl_FTTransformer__absperf</th>\n",
       "      <th>rtdl_MLP__absperf</th>\n",
       "      <th>rtdl_ResNet__absperf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openml__Amazon_employee_access__34539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openml__Australian__146818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openml__GesturePhaseSegmentationProcessed__14969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openml__JapaneseVowels__3510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openml__LED-display-domain-7digit__125921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>openml__walking-activity__9945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>openml__wall-robot-navigation__9960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>openml__wdbc__9946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>openml__yeast__145793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dataset_name  LinearModel__absperf  \\\n",
       "0               openml__Amazon_employee_access__34539                   1.0   \n",
       "1                          openml__Australian__146818                   1.0   \n",
       "2    openml__GesturePhaseSegmentationProcessed__14969                   0.0   \n",
       "3                        openml__JapaneseVowels__3510                   1.0   \n",
       "4           openml__LED-display-domain-7digit__125921                   0.0   \n",
       "..                                                ...                   ...   \n",
       "129                    openml__walking-activity__9945                   0.0   \n",
       "130               openml__wall-robot-navigation__9960                   0.0   \n",
       "131                                openml__wdbc__9946                   1.0   \n",
       "132                              openml__wilt__146820                   1.0   \n",
       "133                             openml__yeast__145793                   0.0   \n",
       "\n",
       "     RandomForest__absperf  XGBoost__absperf  rtdl_FTTransformer__absperf  \\\n",
       "0                      1.0               1.0                          1.0   \n",
       "1                      1.0               0.0                          0.0   \n",
       "2                      0.0               0.0                          0.0   \n",
       "3                      0.0               1.0                          1.0   \n",
       "4                      0.0               0.0                          0.0   \n",
       "..                     ...               ...                          ...   \n",
       "129                    0.0               0.0                          0.0   \n",
       "130                    1.0               1.0                          0.0   \n",
       "131                    1.0               1.0                          1.0   \n",
       "132                    1.0               1.0                          1.0   \n",
       "133                    0.0               0.0                          0.0   \n",
       "\n",
       "     rtdl_MLP__absperf  rtdl_ResNet__absperf  \n",
       "0                  1.0                   1.0  \n",
       "1                  1.0                   0.0  \n",
       "2                  0.0                   0.0  \n",
       "3                  1.0                   1.0  \n",
       "4                  0.0                   0.0  \n",
       "..                 ...                   ...  \n",
       "129                0.0                   0.0  \n",
       "130                1.0                   1.0  \n",
       "131                1.0                   1.0  \n",
       "132                1.0                   1.0  \n",
       "133                0.0                   0.0  \n",
       "\n",
       "[134 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = targets[['dataset_name', 'XGBoost__absperf']]\n",
    "df = X.merge(y, how='inner', on='dataset_name')\n",
    "df = df.drop(columns=['dataset_name'])\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df['XGBoost__absperf'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load and prepare data\n",
    "# data = load_breast_cancer()\n",
    "# X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuration\n",
    "NUM_FEATURES = X.shape[1]\n",
    "CF_STEPS = 500\n",
    "TRAIN_EPOCHS = 300\n",
    "ALPHA = 0.01  # Feature count penalty coefficient\n",
    "DC = 0.2\n",
    "# Define neural network model\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Batched counterfactual generator\n",
    "def generate_counterfactual_batch(model, x_original_batch, target_class_batch, mad, steps=CF_STEPS, distance_coef = DC):\n",
    "    x_cf = x_original_batch.clone().detach().to(device).requires_grad_(True)\n",
    "    optimizer = optim.Adam([x_cf], lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_cf)\n",
    "        pred_loss = criterion(logits, target_class_batch)\n",
    "        # Compute distance loss in a batched way\n",
    "        distance_loss = (((x_cf - x_original_batch).abs() / mad).sum(dim=1)).mean()\n",
    "        loss = pred_loss + distance_coef*distance_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return x_cf.detach()\n",
    "\n",
    "# Evaluate a candidate feature subset (in this case, typically one feature)\n",
    "def evaluate_feature_subset(feature_mask):\n",
    "    if feature_mask.sum() == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train_masked = X_train[:, feature_mask]\n",
    "    #X_val_scaled = scaler.transform(X_val[:, feature_mask])\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train_masked).to(device)\n",
    "    y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "    #X_val_tensor = torch.FloatTensor(X_val_scaled).to(device)\n",
    "\n",
    "    # Train the model on the selected feature subset\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = ClassificationModel(feature_mask.sum()).to(device)\n",
    "    optimizer_model = optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(TRAIN_EPOCHS):\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer_model.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer_model.step()\n",
    "    \n",
    "    # Compute median absolute deviation (MAD) for the training data\n",
    "    med = torch.median(X_train_tensor, dim=0).values\n",
    "    mad = torch.median(torch.abs(X_train_tensor - med) + 1e-6, dim=0).values\n",
    "\n",
    "    # --- Batched counterfactual evaluation ---\n",
    "    batch_instances = X_train_tensor\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch_instances)\n",
    "        original_classes = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n",
    "    \n",
    "    # Define target class as the opposite class\n",
    "    target_tensor = ((original_classes + 1) % 2).to(device)\n",
    "    # Generate counterfactuals for the entire batch at once\n",
    "    cf_batch = generate_counterfactual_batch(model, batch_instances, target_tensor, mad, CF_STEPS)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits_cf = model(cf_batch)\n",
    "        cf_classes = torch.argmax(torch.softmax(logits_cf, dim=-1), dim=-1)\n",
    "    \n",
    "    correct = (cf_classes == target_tensor).float().sum().item()\n",
    "    cf_accuracy = correct / X_train_tensor.shape[0]\n",
    "    # Apply a penalty proportional to the fraction of features used (for one feature, penalty is constant)\n",
    "    fitness = cf_accuracy\n",
    "    return fitness\n",
    "\n",
    "# New selection strategy: Evaluate each individual feature and select the top K\n",
    "def select_top_k_features(K):\n",
    "    fitness_results = {}\n",
    "    # Evaluate each feature in parallel (each candidate mask uses a single feature)\n",
    "    with ThreadPoolExecutor(max_workers=NUM_FEATURES) as executor:\n",
    "        futures = {}\n",
    "        for feat in range(NUM_FEATURES):\n",
    "            # Create a mask with only this feature selected\n",
    "            mask = np.zeros(NUM_FEATURES, dtype=bool)\n",
    "            mask[feat] = True\n",
    "            futures[executor.submit(evaluate_feature_subset, mask)] = feat\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            feat = futures[future]\n",
    "            try:\n",
    "                fitness = future.result()\n",
    "                fitness_results[feat] = fitness\n",
    "                print(f\"Feature {feat} fitness: {fitness:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Feature {feat} evaluation failed: {e}\")\n",
    "\n",
    "    # Sort features by fitness (higher is better)\n",
    "    sorted_features = sorted(fitness_results.items(), key=lambda x: x[1], reverse=True)\n",
    "    selected_features = np.zeros(NUM_FEATURES, dtype=bool)\n",
    "    for i in range(min(K, len(sorted_features))):\n",
    "        feat, fitness = sorted_features[i]\n",
    "        selected_features[feat] = True\n",
    "        print(f\"Selected feature {feat} with fitness {fitness:.4f}\")\n",
    "\n",
    "    return selected_features, sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 7 fitness: 0.0000\n",
      "Feature 41 fitness: 1.0000\n",
      "Feature 24 fitness: 1.0000\n",
      "Feature 30 fitness: 1.0000\n",
      "Feature 0 fitness: 0.0000\n",
      "Feature 29 fitness: 1.0000\n",
      "Feature 78 fitness: 0.0000\n",
      "Feature 102 fitness: 0.0000\n",
      "Feature 77 fitness: 0.0000\n",
      "Feature 54 fitness: 0.0000\n",
      "Feature 31 fitness: 0.0000\n",
      "Feature 8 fitness: 1.0000\n",
      "Feature 17 fitness: 1.0000\n",
      "Feature 53 fitness: 0.0000\n",
      "Feature 6 fitness: 0.0000\n",
      "Feature 23 fitness: 0.0000\n",
      "Feature 19 fitness: 1.0000\n",
      "Feature 35 fitness: 0.0000\n",
      "Feature 5 fitness: 0.0000\n",
      "Feature 1 fitness: 1.0000\n",
      "Feature 11 fitness: 1.0000\n",
      "Feature 48 fitness: 1.0000\n",
      "Feature 42 fitness: 0.0000\n",
      "Feature 25 fitness: 0.0000\n",
      "Feature 91 fitness: 0.0000\n",
      "Feature 32 fitness: 0.0000\n",
      "Feature 67 fitness: 0.0000\n",
      "Feature 66 fitness: 0.0000\n",
      "Feature 18 fitness: 0.0093\n",
      "Feature 114 fitness: 1.0000\n",
      "Feature 120 fitness: 0.0000\n",
      "Feature 38 fitness: 0.0000\n",
      "Feature 108 fitness: 0.0093\n",
      "Feature 49 fitness: 0.0000\n",
      "Feature 89 fitness: 0.0000\n",
      "Feature 80 fitness: 0.0000\n",
      "Feature 65 fitness: 0.0000\n",
      "Feature 84 fitness: 0.0093\n",
      "Feature 103 fitness: 0.0000\n",
      "Feature 90 fitness: 0.0000\n",
      "Feature 60 fitness: 0.0000\n",
      "Feature 44 fitness: 1.0000\n",
      "Feature 95 fitness: 1.0000\n",
      "Feature 115 fitness: 1.0000\n",
      "Feature 12 fitness: 0.0000\n",
      "Feature 55 fitness: 1.0000\n",
      "Feature 92 fitness: 0.0000\n",
      "Feature 13 fitness: 0.0000\n",
      "Feature 83 fitness: 1.0000\n",
      "Feature 116 fitness: 0.0000\n",
      "Feature 72 fitness: 0.0000\n",
      "Feature 2 fitness: 0.0000\n",
      "Feature 85 fitness: 0.0093\n",
      "Feature 71 fitness: 0.0000\n",
      "Feature 47 fitness: 0.0000\n",
      "Feature 113 fitness: 0.0000\n",
      "Feature 101 fitness: 0.0093\n",
      "Feature 37 fitness: 0.1869\n",
      "Feature 81 fitness: 0.0000\n",
      "Feature 14 fitness: 1.0000\n",
      "Feature 43 fitness: 0.0000\n",
      "Feature 109 fitness: 0.0000\n",
      "Feature 79 fitness: 0.0000\n",
      "Feature 36 fitness: 0.0000\n",
      "Feature 96 fitness: 0.0000\n",
      "Feature 56 fitness: 0.0000\n",
      "Feature 51 fitness: 0.0000\n",
      "Feature 104 fitness: 0.0000\n",
      "Feature 59 fitness: 1.0000\n",
      "Feature 62 fitness: 0.0000\n",
      "Feature 107 fitness: 0.0000\n",
      "Feature 61 fitness: 1.0000\n",
      "Feature 97 fitness: 0.0000\n",
      "Feature 20 fitness: 1.0000\n",
      "Feature 26 fitness: 0.0000\n",
      "Feature 33 fitness: 1.0000\n",
      "Feature 73 fitness: 0.0000\n",
      "Feature 105 fitness: 0.0000\n",
      "Feature 15 fitness: 0.0000\n",
      "Feature 119 fitness: 0.0000\n",
      "Feature 68 fitness: 1.0000\n",
      "Feature 57 fitness: 0.0000\n",
      "Feature 9 fitness: 0.0000\n",
      "Feature 121 fitness: 0.0000\n",
      "Feature 50 fitness: 0.0000\n",
      "Feature 98 fitness: 0.0000\n",
      "Feature 45 fitness: 0.0000\n",
      "Feature 74 fitness: 0.0000\n",
      "Feature 110 fitness: 0.0093\n",
      "Feature 69 fitness: 1.0000\n",
      "Feature 21 fitness: 0.0000\n",
      "Feature 122 fitness: 0.0000\n",
      "Feature 117 fitness: 0.0000\n",
      "Feature 3 fitness: 1.0000\n",
      "Feature 63 fitness: 0.0000\n",
      "Feature 27 fitness: 1.0000\n",
      "Feature 99 fitness: 0.0093\n",
      "Feature 86 fitness: 1.0000\n",
      "Feature 75 fitness: 0.0000\n",
      "Feature 39 fitness: 0.0000\n",
      "Feature 87 fitness: 0.0000\n",
      "Feature 93 fitness: 0.0000\n",
      "Feature 111 fitness: 0.0000\n",
      "Feature 76 fitness: 0.0000\n",
      "Feature 28 fitness: 0.0000\n",
      "Feature 64 fitness: 0.0000\n",
      "Feature 4 fitness: 0.0000\n",
      "Feature 40 fitness: 1.0000\n",
      "Feature 16 fitness: 0.0000\n",
      "Feature 100 fitness: 0.0000\n",
      "Feature 58 fitness: 1.0000\n",
      "Feature 88 fitness: 0.0000\n",
      "Feature 34 fitness: 0.0000\n",
      "Feature 112 fitness: 0.0093\n",
      "Feature 94 fitness: 1.0000\n",
      "Feature 46 fitness: 1.0000\n",
      "Feature 118 fitness: 0.0000\n",
      "Feature 106 fitness: 1.0000\n",
      "Feature 52 fitness: 0.0000\n",
      "Feature 22 fitness: 0.0000\n",
      "Feature 10 fitness: 1.0000\n",
      "Feature 70 fitness: 0.0000\n",
      "Feature 82 fitness: 0.0000\n",
      "Selected feature 41 with fitness 1.0000\n",
      "Selected feature 24 with fitness 1.0000\n",
      "Selected feature 30 with fitness 1.0000\n",
      "Selected feature 29 with fitness 1.0000\n",
      "Selected feature 8 with fitness 1.0000\n",
      "Final selected features mask: [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False  True  True False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False]\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 5\n",
    "final_selected_features, sorted_fitness = select_top_k_features(TOP_K)\n",
    "print(\"Final selected features mask:\", final_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x28596945d50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot([x[1] for x in sorted_fitness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 0.9996666666666667),\n",
       " (27, 0.9996666666666667),\n",
       " (7, 0.9996666666666667),\n",
       " (22, 0.9996666666666667),\n",
       " (23, 0.9996666666666667),\n",
       " (2, 0.021644688644688645),\n",
       " (13, 0.010655677655677657),\n",
       " (3, 0.010655677655677657),\n",
       " (29, 0.010655677655677657),\n",
       " (12, 0.010655677655677657),\n",
       " (19, -0.0003333333333333333),\n",
       " (9, -0.0003333333333333333),\n",
       " (8, -0.0003333333333333333),\n",
       " (21, -0.0003333333333333333),\n",
       " (26, -0.0003333333333333333),\n",
       " (14, -0.0003333333333333333),\n",
       " (25, -0.0003333333333333333),\n",
       " (1, -0.0003333333333333333),\n",
       " (15, -0.0003333333333333333),\n",
       " (10, -0.0003333333333333333),\n",
       " (4, -0.0003333333333333333),\n",
       " (16, -0.0003333333333333333),\n",
       " (28, -0.0003333333333333333),\n",
       " (11, -0.0003333333333333333),\n",
       " (5, -0.0003333333333333333),\n",
       " (17, -0.0003333333333333333),\n",
       " (0, -0.0003333333333333333),\n",
       " (6, -0.0003333333333333333),\n",
       " (18, -0.0003333333333333333),\n",
       " (24, -0.0003333333333333333)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_fitness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_shift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
